{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "AIDEVS_API_KEY = os.environ[\"AIDEVS_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'please return transcription of this file: https://tasks.aidevs.pl/data/mateusz.mp3', 'hint': 'use WHISPER model - https://platform.openai.com/docs/guides/speech-to-text'}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\"https://tasks.aidevs.pl/token/whisper\", json=dict(apikey=AIDEVS_API_KEY))\n",
    "response_json = json.loads(response.text)\n",
    "token = response_json[\"token\"]\n",
    "\n",
    "response = requests.get(f\"https://tasks.aidevs.pl/task/{token}\")\n",
    "response_json = json.loads(response.text)\n",
    "\n",
    "print(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_url = response_json[\"msg\"].split(\"please return transcription of this file: \")[1]\n",
    "response = requests.get(mp3_url, params={\"downloadformat\": \"mp3\"})\n",
    "\n",
    "if response.ok:\n",
    "    with open(\"task-mp3-file.mp3\", mode=\"wb\") as file:\n",
    "        file.write(response.content)\n",
    "else:\n",
    "    print(f\"Response error, status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cześć! Kiedy ostatnio korzystaliście z sztucznej inteligencji, czy zastanawialiście się nad tym, skąd czerpie ona swoją wiedzę? No pewnie, że tak, inaczej nie byłoby was tutaj na szkoleniu. Ale czy przemyśleliście możliwość dostosowania tej wiedzy do waszych własnych, indywidualnych potrzeb?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"task-mp3-file.mp3\", mode=\"rb\") as file:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "      model=\"whisper-1\", \n",
    "      file=file, \n",
    "      response_format=\"text\"\n",
    "    )\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"code\": 0,\n",
      "    \"msg\": \"OK\",\n",
      "    \"note\": \"CORRECT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"https://tasks.aidevs.pl/answer/{token}\", json=dict(answer=transcription))\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai-devs-2]",
   "language": "python",
   "name": "conda-env-ai-devs-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
